# 04 â€” Temporal Embedding

Transform sequential inputs into embedded temporal representations before graph-temporal fusion.

## Existing references
- `data&preprocessing/social/external_gcn_attention_model.py`
- `data&preprocessing/social/external_gcn_with_attention_crime_analysis.py`

These scripts include sequence windowing and feature transformation logic used prior to recurrent learning.
