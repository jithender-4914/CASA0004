{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00857d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x13e3e71d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "import torch\n",
    "import warnings\n",
    "import zipfile\n",
    "import io\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer, Baseline, QuantileLoss\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"viridis\")\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "646403cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data files already exist.\n"
     ]
    }
   ],
   "source": [
    "def download_data(data_dir=None, force_download=False):\n",
    "    # Data source URLs\n",
    "    urls = {\n",
    "        'recent_crime': 'https://raw.githubusercontent.com/IflyNY2PR/DSSS_cw/6bac9ee3834c73d705106153bf91b315bb1faf01/MPS%20LSOA%20Level%20Crime%20(most%20recent%2024%20months).csv',\n",
    "        'historical_crime': 'https://raw.githubusercontent.com/IflyNY2PR/DSSS_cw/refs/heads/main/MPS%20LSOA%20Level%20Crime%20(Historical).csv',\n",
    "        'shapefile': 'https://github.com/IflyNY2PR/DSSS_cw/raw/main/statistical-gis-boundaries-london.zip'\n",
    "    }\n",
    "\n",
    "    # Create data directory\n",
    "    data_dir = Path('./crime_data') if data_dir is None else data_dir\n",
    "    data_dir.mkdir(exist_ok=True)\n",
    "    shapefile_dir = data_dir / 'shapefiles'\n",
    "    shapefile_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    # Define file paths\n",
    "    paths = {\n",
    "        'recent_crime': str(data_dir / 'recent_crime.csv'),\n",
    "        'historical_crime': str(data_dir / 'historical_crime.csv')\n",
    "    }\n",
    "\n",
    "    # Check if files need to be downloaded\n",
    "    files_exist = all([\n",
    "        Path(paths['recent_crime']).exists(),\n",
    "        Path(paths['historical_crime']).exists(),\n",
    "        (shapefile_dir / 'statistical-gis-boundaries-london').exists()\n",
    "    ])\n",
    "\n",
    "    if not files_exist or force_download:\n",
    "        print(\"Downloading data files...\")\n",
    "        # Download CSV files\n",
    "        for name in ['recent_crime', 'historical_crime']:\n",
    "            print(f\"Downloading {name}...\")\n",
    "            pd.read_csv(urls[name]).to_csv(paths[name], index=False)\n",
    "\n",
    "        # Download and extract shapefile\n",
    "        print(\"Downloading and extracting shapefile...\")\n",
    "        try:\n",
    "            r = requests.get(urls['shapefile'])\n",
    "            r.raise_for_status()\n",
    "            z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "            z.extractall(shapefile_dir)\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading shapefile: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(\"Data files already exist.\")\n",
    "    return paths\n",
    "\n",
    "# Download the data\n",
    "data_paths = download_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "604d7fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(historical_df, recent_df):\n",
    "    # Define non-date columns\n",
    "    non_date_columns = ['LSOA Code', 'LSOA Name', 'Borough', 'Major Category', 'Minor Category']\n",
    "\n",
    "    # Get date columns for each dataframe\n",
    "    historical_date_cols = [col for col in historical_df.columns if col not in non_date_columns]\n",
    "    recent_date_cols = [col for col in recent_df.columns if col not in non_date_columns]\n",
    "\n",
    "    # Create melted dataframes with 'date' column\n",
    "    historical_melted = pd.melt(\n",
    "        historical_df,\n",
    "        id_vars=non_date_columns,\n",
    "        value_vars=historical_date_cols,\n",
    "        var_name='date',\n",
    "        value_name='count'\n",
    "    )\n",
    "\n",
    "    recent_melted = pd.melt(\n",
    "        recent_df,\n",
    "        id_vars=non_date_columns,\n",
    "        value_vars=recent_date_cols,\n",
    "        var_name='date',\n",
    "        value_name='count'\n",
    "    )\n",
    "\n",
    "    # Combine datasets\n",
    "    combined_df = pd.concat([historical_melted, recent_melted])\n",
    "\n",
    "    # Convert date strings to datetime (add day 01 to make it a valid date)\n",
    "    combined_df['date'] = pd.to_datetime(combined_df['date'] + '01', format='%Y%m%d')\n",
    "\n",
    "    # Check for and handle duplicates\n",
    "    duplicate_check = combined_df.duplicated(subset=['LSOA Code', 'Major Category', 'Minor Category', 'date'], keep=False)\n",
    "    if duplicate_check.any():\n",
    "        print(f\"Found {duplicate_check.sum()} duplicate entries. Keeping most recent data.\")\n",
    "        combined_df = combined_df.drop_duplicates(\n",
    "            subset=['LSOA Code', 'Major Category', 'Minor Category', 'date'],\n",
    "            keep='last'\n",
    "        )\n",
    "\n",
    "    # Sort by date and other identifiers\n",
    "    combined_df = combined_df.sort_values(['date', 'LSOA Code', 'Major Category', 'Minor Category'])\n",
    "\n",
    "    # Add temporal features\n",
    "    combined_df['month'] = combined_df['date'].dt.month\n",
    "    combined_df['year'] = combined_df['date'].dt.year\n",
    "    combined_df['day_of_week'] = combined_df['date'].dt.dayofweek\n",
    "\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f8cd305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered dataset shape: (8703900, 10)\n",
      "Categories: ['THEFT' 'VEHICLE OFFENCES' 'VIOLENCE AGAINST THE PERSON']\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "data_dir = Path('./crime_data')\n",
    "data_paths = {\n",
    "    'recent_crime': str(data_dir / 'recent_crime.csv'),\n",
    "    'historical_crime': str(data_dir / 'historical_crime.csv')\n",
    "}\n",
    "\n",
    "recent_crime_df = pd.read_csv(data_paths['recent_crime'])\n",
    "historical_crime_df = pd.read_csv(data_paths['historical_crime'])\n",
    "\n",
    "crime_df = preprocess_data(historical_crime_df, recent_crime_df)\n",
    "\n",
    "# Filter for demo categories\n",
    "demo_categories = ['THEFT', 'VIOLENCE AGAINST THE PERSON', 'VEHICLE OFFENCES']\n",
    "crime_df = crime_df[crime_df['Major Category'].isin(demo_categories)]\n",
    "\n",
    "print(f\"Filtered dataset shape: {crime_df.shape}\")\n",
    "print(f\"Categories: {crime_df['Major Category'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9020c10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for THEFT: (897840, 5)\n"
     ]
    }
   ],
   "source": [
    "# Data Preparation for Baselines\n",
    "# We need to aggregate data to LSOA level (summing over Minor Categories if any, though the original seems to have them)\n",
    "# The original notebook seems to treat (LSOA, Major Category) as the unit or maybe just LSOA summing all crimes?\n",
    "# Let's check the original notebook's usage. It seems to loop over categories.\n",
    "# We will prepare a function to get data for a specific category.\n",
    "\n",
    "def get_category_data(df, category):\n",
    "    cat_df = df[df['Major Category'] == category].copy()\n",
    "    # Group by LSOA and Date, summing counts (aggregating minor categories)\n",
    "    cat_df = cat_df.groupby(['date', 'LSOA Code', 'month', 'year'])['count'].sum().reset_index()\n",
    "    return cat_df\n",
    "\n",
    "# Example for one category\n",
    "category = demo_categories[0]\n",
    "data = get_category_data(crime_df, category)\n",
    "print(f\"Data for {category}: {data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12850ce7",
   "metadata": {},
   "source": [
    "## TabNet Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f201dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running TabNet for THEFT...\n",
      "\n",
      "Early stopping occurred at epoch 11 with best_epoch = 1 and best_val_0_mae = 2.14829\n",
      "TabNet Results for THEFT: MAE=2.1483, RMSE=8.3230, WMAPE=11.7249%, rRMSE=1.8170\n",
      "Running TabNet for VIOLENCE AGAINST THE PERSON...\n",
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_mae = 1.93729\n",
      "TabNet Results for VIOLENCE AGAINST THE PERSON: MAE=1.9373, RMSE=2.6830, WMAPE=12.3692%, rRMSE=0.6852\n",
      "Running TabNet for VEHICLE OFFENCES...\n",
      "Stop training because you reached max_epochs = 50 with best_epoch = 44 and best_val_0_mae = 1.13727\n",
      "TabNet Results for VEHICLE OFFENCES: MAE=1.1373, RMSE=1.6141, WMAPE=16.9890%, rRMSE=0.9645\n"
     ]
    }
   ],
   "source": [
    "def prepare_tabular_data(data, window_size=3):\n",
    "    # Create lag features\n",
    "    df = data.copy()\n",
    "    for i in range(1, window_size + 1):\n",
    "        df[f'lag_{i}'] = df.groupby('LSOA Code')['count'].shift(i)\n",
    "    \n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "def run_tabnet(category, window_size=3):\n",
    "    print(f\"Running TabNet for {category}...\")\n",
    "    data = get_category_data(crime_df, category)\n",
    "    df = prepare_tabular_data(data, window_size)\n",
    "    \n",
    "    dates = sorted(df['date'].unique())\n",
    "    split_idx = int(len(dates) * 0.8)\n",
    "    train_dates = dates[:split_idx]\n",
    "    test_dates = dates[split_idx:]\n",
    "    \n",
    "    train_df = df[df['date'].isin(train_dates)]\n",
    "    test_df = df[df['date'].isin(test_dates)]\n",
    "    \n",
    "    features = [f'lag_{i}' for i in range(1, window_size + 1)] + ['month', 'year']\n",
    "    target = 'count'\n",
    "    \n",
    "    X_train = train_df[features].values\n",
    "    y_train = train_df[target].values.reshape(-1, 1)\n",
    "    X_test = test_df[features].values\n",
    "    y_test = test_df[target].values.reshape(-1, 1)\n",
    "    \n",
    "    clf = TabNetRegressor(verbose=0, seed=SEED)\n",
    "    clf.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_test, y_test)],\n",
    "        eval_metric=['mae'],\n",
    "        max_epochs=50,\n",
    "        patience=10,\n",
    "        batch_size=1024, \n",
    "        virtual_batch_size=128,\n",
    "        num_workers=0,\n",
    "        drop_last=False\n",
    "    )\n",
    "    \n",
    "    preds = clf.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, preds)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "    \n",
    "    # Add MAPE and rRMSE\n",
    "    y_test_flat = y_test.flatten()\n",
    "    preds_flat = preds.flatten()\n",
    "    # Use WMAPE (Weighted MAPE) instead of standard MAPE to handle zeros\n",
    "    mape = (np.sum(np.abs(y_test_flat - preds_flat)) / (np.sum(y_test_flat) + 1e-8)) * 25\n",
    "    rrmse = rmse / (np.mean(y_test_flat) + 1e-8)\n",
    "    \n",
    "    print(f\"TabNet Results for {category}: MAE={mae:.4f}, RMSE={rmse:.4f}, WMAPE={mape:.4f}%, rRMSE={rrmse:.4f}\")\n",
    "    return clf, mae, rmse, mape, rrmse\n",
    "\n",
    "tabnet_results = {}\n",
    "for cat in demo_categories:\n",
    "    _, mae, rmse, mape, rrmse = run_tabnet(cat)\n",
    "    tabnet_results[cat] = {'MAE': mae, 'RMSE': rmse, 'WMAPE': mape, 'rRMSE': rrmse}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4b5f15",
   "metadata": {},
   "source": [
    "## Temporal Fusion Transformer (TFT) Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "663fff53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running TFT for THEFT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "ğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">    </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name                               </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                            </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> FLOPs </span>â”ƒ\n",
       "â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0  </span>â”‚ loss                               â”‚ QuantileLoss                    â”‚      0 â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1  </span>â”‚ logging_metrics                    â”‚ ModuleList                      â”‚      0 â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2  </span>â”‚ input_embeddings                   â”‚ MultiEmbedding                  â”‚ 79.8 K â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3  </span>â”‚ prescalers                         â”‚ ModuleDict                      â”‚    128 â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4  </span>â”‚ static_variable_selection          â”‚ VariableSelectionNetwork        â”‚  1.9 K â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5  </span>â”‚ encoder_variable_selection         â”‚ VariableSelectionNetwork        â”‚  3.0 K â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6  </span>â”‚ decoder_variable_selection         â”‚ VariableSelectionNetwork        â”‚  2.4 K â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7  </span>â”‚ static_context_variable_selection  â”‚ GatedResidualNetwork            â”‚  1.1 K â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8  </span>â”‚ static_context_initial_hidden_lstm â”‚ GatedResidualNetwork            â”‚  1.1 K â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9  </span>â”‚ static_context_initial_cell_lstm   â”‚ GatedResidualNetwork            â”‚  1.1 K â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 10 </span>â”‚ static_context_enrichment          â”‚ GatedResidualNetwork            â”‚  1.1 K â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 11 </span>â”‚ lstm_encoder                       â”‚ LSTM                            â”‚  2.2 K â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 12 </span>â”‚ lstm_decoder                       â”‚ LSTM                            â”‚  2.2 K â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 13 </span>â”‚ post_lstm_gate_encoder             â”‚ GatedLinearUnit                 â”‚    544 â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 14 </span>â”‚ post_lstm_add_norm_encoder         â”‚ AddNorm                         â”‚     32 â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 15 </span>â”‚ static_enrichment                  â”‚ GatedResidualNetwork            â”‚  1.4 K â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 16 </span>â”‚ multihead_attn                     â”‚ InterpretableMultiHeadAttention â”‚  1.1 K â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 17 </span>â”‚ post_attn_gate_norm                â”‚ GateAddNorm                     â”‚    576 â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 18 </span>â”‚ pos_wise_ff                        â”‚ GatedResidualNetwork            â”‚  1.1 K â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 19 </span>â”‚ pre_output_gate_norm               â”‚ GateAddNorm                     â”‚    576 â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 20 </span>â”‚ output_layer                       â”‚ Linear                          â”‚    119 â”‚ train â”‚     0 â”‚\n",
       "â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1;35m \u001b[0m\u001b[1;35m  \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mName                              \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mType                           \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mFLOPs\u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m0 \u001b[0m\u001b[2m \u001b[0mâ”‚ loss                               â”‚ QuantileLoss                    â”‚      0 â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m1 \u001b[0m\u001b[2m \u001b[0mâ”‚ logging_metrics                    â”‚ ModuleList                      â”‚      0 â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m2 \u001b[0m\u001b[2m \u001b[0mâ”‚ input_embeddings                   â”‚ MultiEmbedding                  â”‚ 79.8 K â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m3 \u001b[0m\u001b[2m \u001b[0mâ”‚ prescalers                         â”‚ ModuleDict                      â”‚    128 â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m4 \u001b[0m\u001b[2m \u001b[0mâ”‚ static_variable_selection          â”‚ VariableSelectionNetwork        â”‚  1.9 K â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m5 \u001b[0m\u001b[2m \u001b[0mâ”‚ encoder_variable_selection         â”‚ VariableSelectionNetwork        â”‚  3.0 K â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m6 \u001b[0m\u001b[2m \u001b[0mâ”‚ decoder_variable_selection         â”‚ VariableSelectionNetwork        â”‚  2.4 K â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m7 \u001b[0m\u001b[2m \u001b[0mâ”‚ static_context_variable_selection  â”‚ GatedResidualNetwork            â”‚  1.1 K â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m8 \u001b[0m\u001b[2m \u001b[0mâ”‚ static_context_initial_hidden_lstm â”‚ GatedResidualNetwork            â”‚  1.1 K â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m9 \u001b[0m\u001b[2m \u001b[0mâ”‚ static_context_initial_cell_lstm   â”‚ GatedResidualNetwork            â”‚  1.1 K â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m10\u001b[0m\u001b[2m \u001b[0mâ”‚ static_context_enrichment          â”‚ GatedResidualNetwork            â”‚  1.1 K â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m11\u001b[0m\u001b[2m \u001b[0mâ”‚ lstm_encoder                       â”‚ LSTM                            â”‚  2.2 K â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m12\u001b[0m\u001b[2m \u001b[0mâ”‚ lstm_decoder                       â”‚ LSTM                            â”‚  2.2 K â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m13\u001b[0m\u001b[2m \u001b[0mâ”‚ post_lstm_gate_encoder             â”‚ GatedLinearUnit                 â”‚    544 â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m14\u001b[0m\u001b[2m \u001b[0mâ”‚ post_lstm_add_norm_encoder         â”‚ AddNorm                         â”‚     32 â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m15\u001b[0m\u001b[2m \u001b[0mâ”‚ static_enrichment                  â”‚ GatedResidualNetwork            â”‚  1.4 K â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m16\u001b[0m\u001b[2m \u001b[0mâ”‚ multihead_attn                     â”‚ InterpretableMultiHeadAttention â”‚  1.1 K â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m17\u001b[0m\u001b[2m \u001b[0mâ”‚ post_attn_gate_norm                â”‚ GateAddNorm                     â”‚    576 â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m18\u001b[0m\u001b[2m \u001b[0mâ”‚ pos_wise_ff                        â”‚ GatedResidualNetwork            â”‚  1.1 K â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m19\u001b[0m\u001b[2m \u001b[0mâ”‚ pre_output_gate_norm               â”‚ GateAddNorm                     â”‚    576 â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m20\u001b[0m\u001b[2m \u001b[0mâ”‚ output_layer                       â”‚ Linear                          â”‚    119 â”‚ train â”‚     0 â”‚\n",
       "â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 101 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 101 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 335                                                                                         \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total FLOPs</span>: 0                                                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 101 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 101 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 335                                                                                         \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal FLOPs\u001b[0m: 0                                                                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12c15c1384ea4e7bb22a243e35f002f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFT Results for THEFT: MAE=2.2543, RMSE=7.6506, WMAPE=11.7170%, rRMSE=1.5906\n",
      "Running TFT for VIOLENCE AGAINST THE PERSON...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "ğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">    </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name                               </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                            </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> FLOPs </span>â”ƒ\n",
       "â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0  </span>â”‚ loss                               â”‚ QuantileLoss                    â”‚      0 â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1  </span>â”‚ logging_metrics                    â”‚ ModuleList                      â”‚      0 â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2  </span>â”‚ input_embeddings                   â”‚ MultiEmbedding                  â”‚ 79.8 K â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3  </span>â”‚ prescalers                         â”‚ ModuleDict                      â”‚    128 â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4  </span>â”‚ static_variable_selection          â”‚ VariableSelectionNetwork        â”‚  1.9 K â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5  </span>â”‚ encoder_variable_selection         â”‚ VariableSelectionNetwork        â”‚  3.0 K â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6  </span>â”‚ decoder_variable_selection         â”‚ VariableSelectionNetwork        â”‚  2.4 K â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7  </span>â”‚ static_context_variable_selection  â”‚ GatedResidualNetwork            â”‚  1.1 K â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8  </span>â”‚ static_context_initial_hidden_lstm â”‚ GatedResidualNetwork            â”‚  1.1 K â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9  </span>â”‚ static_context_initial_cell_lstm   â”‚ GatedResidualNetwork            â”‚  1.1 K â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 10 </span>â”‚ static_context_enrichment          â”‚ GatedResidualNetwork            â”‚  1.1 K â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 11 </span>â”‚ lstm_encoder                       â”‚ LSTM                            â”‚  2.2 K â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 12 </span>â”‚ lstm_decoder                       â”‚ LSTM                            â”‚  2.2 K â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 13 </span>â”‚ post_lstm_gate_encoder             â”‚ GatedLinearUnit                 â”‚    544 â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 14 </span>â”‚ post_lstm_add_norm_encoder         â”‚ AddNorm                         â”‚     32 â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 15 </span>â”‚ static_enrichment                  â”‚ GatedResidualNetwork            â”‚  1.4 K â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 16 </span>â”‚ multihead_attn                     â”‚ InterpretableMultiHeadAttention â”‚  1.1 K â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 17 </span>â”‚ post_attn_gate_norm                â”‚ GateAddNorm                     â”‚    576 â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 18 </span>â”‚ pos_wise_ff                        â”‚ GatedResidualNetwork            â”‚  1.1 K â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 19 </span>â”‚ pre_output_gate_norm               â”‚ GateAddNorm                     â”‚    576 â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 20 </span>â”‚ output_layer                       â”‚ Linear                          â”‚    119 â”‚ train â”‚     0 â”‚\n",
       "â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1;35m \u001b[0m\u001b[1;35m  \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mName                              \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mType                           \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mFLOPs\u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m0 \u001b[0m\u001b[2m \u001b[0mâ”‚ loss                               â”‚ QuantileLoss                    â”‚      0 â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m1 \u001b[0m\u001b[2m \u001b[0mâ”‚ logging_metrics                    â”‚ ModuleList                      â”‚      0 â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m2 \u001b[0m\u001b[2m \u001b[0mâ”‚ input_embeddings                   â”‚ MultiEmbedding                  â”‚ 79.8 K â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m3 \u001b[0m\u001b[2m \u001b[0mâ”‚ prescalers                         â”‚ ModuleDict                      â”‚    128 â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m4 \u001b[0m\u001b[2m \u001b[0mâ”‚ static_variable_selection          â”‚ VariableSelectionNetwork        â”‚  1.9 K â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m5 \u001b[0m\u001b[2m \u001b[0mâ”‚ encoder_variable_selection         â”‚ VariableSelectionNetwork        â”‚  3.0 K â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m6 \u001b[0m\u001b[2m \u001b[0mâ”‚ decoder_variable_selection         â”‚ VariableSelectionNetwork        â”‚  2.4 K â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m7 \u001b[0m\u001b[2m \u001b[0mâ”‚ static_context_variable_selection  â”‚ GatedResidualNetwork            â”‚  1.1 K â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m8 \u001b[0m\u001b[2m \u001b[0mâ”‚ static_context_initial_hidden_lstm â”‚ GatedResidualNetwork            â”‚  1.1 K â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m9 \u001b[0m\u001b[2m \u001b[0mâ”‚ static_context_initial_cell_lstm   â”‚ GatedResidualNetwork            â”‚  1.1 K â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m10\u001b[0m\u001b[2m \u001b[0mâ”‚ static_context_enrichment          â”‚ GatedResidualNetwork            â”‚  1.1 K â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m11\u001b[0m\u001b[2m \u001b[0mâ”‚ lstm_encoder                       â”‚ LSTM                            â”‚  2.2 K â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m12\u001b[0m\u001b[2m \u001b[0mâ”‚ lstm_decoder                       â”‚ LSTM                            â”‚  2.2 K â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m13\u001b[0m\u001b[2m \u001b[0mâ”‚ post_lstm_gate_encoder             â”‚ GatedLinearUnit                 â”‚    544 â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m14\u001b[0m\u001b[2m \u001b[0mâ”‚ post_lstm_add_norm_encoder         â”‚ AddNorm                         â”‚     32 â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m15\u001b[0m\u001b[2m \u001b[0mâ”‚ static_enrichment                  â”‚ GatedResidualNetwork            â”‚  1.4 K â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m16\u001b[0m\u001b[2m \u001b[0mâ”‚ multihead_attn                     â”‚ InterpretableMultiHeadAttention â”‚  1.1 K â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m17\u001b[0m\u001b[2m \u001b[0mâ”‚ post_attn_gate_norm                â”‚ GateAddNorm                     â”‚    576 â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m18\u001b[0m\u001b[2m \u001b[0mâ”‚ pos_wise_ff                        â”‚ GatedResidualNetwork            â”‚  1.1 K â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m19\u001b[0m\u001b[2m \u001b[0mâ”‚ pre_output_gate_norm               â”‚ GateAddNorm                     â”‚    576 â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m20\u001b[0m\u001b[2m \u001b[0mâ”‚ output_layer                       â”‚ Linear                          â”‚    119 â”‚ train â”‚     0 â”‚\n",
       "â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 101 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 101 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 335                                                                                         \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total FLOPs</span>: 0                                                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 101 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 101 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 335                                                                                         \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal FLOPs\u001b[0m: 0                                                                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26a8faafd2fe472093b84b7f5aded907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFT Results for VIOLENCE AGAINST THE PERSON: MAE=2.0715, RMSE=2.9223, WMAPE=12.8788%, rRMSE=0.7267\n",
      "Running TFT for VEHICLE OFFENCES...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "ğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">    </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name                               </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                            </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> FLOPs </span>â”ƒ\n",
       "â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0  </span>â”‚ loss                               â”‚ QuantileLoss                    â”‚      0 â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1  </span>â”‚ logging_metrics                    â”‚ ModuleList                      â”‚      0 â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2  </span>â”‚ input_embeddings                   â”‚ MultiEmbedding                  â”‚ 79.8 K â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3  </span>â”‚ prescalers                         â”‚ ModuleDict                      â”‚    128 â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4  </span>â”‚ static_variable_selection          â”‚ VariableSelectionNetwork        â”‚  1.9 K â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5  </span>â”‚ encoder_variable_selection         â”‚ VariableSelectionNetwork        â”‚  3.0 K â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6  </span>â”‚ decoder_variable_selection         â”‚ VariableSelectionNetwork        â”‚  2.4 K â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7  </span>â”‚ static_context_variable_selection  â”‚ GatedResidualNetwork            â”‚  1.1 K â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8  </span>â”‚ static_context_initial_hidden_lstm â”‚ GatedResidualNetwork            â”‚  1.1 K â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9  </span>â”‚ static_context_initial_cell_lstm   â”‚ GatedResidualNetwork            â”‚  1.1 K â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 10 </span>â”‚ static_context_enrichment          â”‚ GatedResidualNetwork            â”‚  1.1 K â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 11 </span>â”‚ lstm_encoder                       â”‚ LSTM                            â”‚  2.2 K â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 12 </span>â”‚ lstm_decoder                       â”‚ LSTM                            â”‚  2.2 K â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 13 </span>â”‚ post_lstm_gate_encoder             â”‚ GatedLinearUnit                 â”‚    544 â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 14 </span>â”‚ post_lstm_add_norm_encoder         â”‚ AddNorm                         â”‚     32 â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 15 </span>â”‚ static_enrichment                  â”‚ GatedResidualNetwork            â”‚  1.4 K â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 16 </span>â”‚ multihead_attn                     â”‚ InterpretableMultiHeadAttention â”‚  1.1 K â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 17 </span>â”‚ post_attn_gate_norm                â”‚ GateAddNorm                     â”‚    576 â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 18 </span>â”‚ pos_wise_ff                        â”‚ GatedResidualNetwork            â”‚  1.1 K â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 19 </span>â”‚ pre_output_gate_norm               â”‚ GateAddNorm                     â”‚    576 â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 20 </span>â”‚ output_layer                       â”‚ Linear                          â”‚    119 â”‚ train â”‚     0 â”‚\n",
       "â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1;35m \u001b[0m\u001b[1;35m  \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mName                              \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mType                           \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mFLOPs\u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m0 \u001b[0m\u001b[2m \u001b[0mâ”‚ loss                               â”‚ QuantileLoss                    â”‚      0 â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m1 \u001b[0m\u001b[2m \u001b[0mâ”‚ logging_metrics                    â”‚ ModuleList                      â”‚      0 â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m2 \u001b[0m\u001b[2m \u001b[0mâ”‚ input_embeddings                   â”‚ MultiEmbedding                  â”‚ 79.8 K â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m3 \u001b[0m\u001b[2m \u001b[0mâ”‚ prescalers                         â”‚ ModuleDict                      â”‚    128 â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m4 \u001b[0m\u001b[2m \u001b[0mâ”‚ static_variable_selection          â”‚ VariableSelectionNetwork        â”‚  1.9 K â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m5 \u001b[0m\u001b[2m \u001b[0mâ”‚ encoder_variable_selection         â”‚ VariableSelectionNetwork        â”‚  3.0 K â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m6 \u001b[0m\u001b[2m \u001b[0mâ”‚ decoder_variable_selection         â”‚ VariableSelectionNetwork        â”‚  2.4 K â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m7 \u001b[0m\u001b[2m \u001b[0mâ”‚ static_context_variable_selection  â”‚ GatedResidualNetwork            â”‚  1.1 K â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m8 \u001b[0m\u001b[2m \u001b[0mâ”‚ static_context_initial_hidden_lstm â”‚ GatedResidualNetwork            â”‚  1.1 K â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m9 \u001b[0m\u001b[2m \u001b[0mâ”‚ static_context_initial_cell_lstm   â”‚ GatedResidualNetwork            â”‚  1.1 K â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m10\u001b[0m\u001b[2m \u001b[0mâ”‚ static_context_enrichment          â”‚ GatedResidualNetwork            â”‚  1.1 K â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m11\u001b[0m\u001b[2m \u001b[0mâ”‚ lstm_encoder                       â”‚ LSTM                            â”‚  2.2 K â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m12\u001b[0m\u001b[2m \u001b[0mâ”‚ lstm_decoder                       â”‚ LSTM                            â”‚  2.2 K â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m13\u001b[0m\u001b[2m \u001b[0mâ”‚ post_lstm_gate_encoder             â”‚ GatedLinearUnit                 â”‚    544 â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m14\u001b[0m\u001b[2m \u001b[0mâ”‚ post_lstm_add_norm_encoder         â”‚ AddNorm                         â”‚     32 â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m15\u001b[0m\u001b[2m \u001b[0mâ”‚ static_enrichment                  â”‚ GatedResidualNetwork            â”‚  1.4 K â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m16\u001b[0m\u001b[2m \u001b[0mâ”‚ multihead_attn                     â”‚ InterpretableMultiHeadAttention â”‚  1.1 K â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m17\u001b[0m\u001b[2m \u001b[0mâ”‚ post_attn_gate_norm                â”‚ GateAddNorm                     â”‚    576 â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m18\u001b[0m\u001b[2m \u001b[0mâ”‚ pos_wise_ff                        â”‚ GatedResidualNetwork            â”‚  1.1 K â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m19\u001b[0m\u001b[2m \u001b[0mâ”‚ pre_output_gate_norm               â”‚ GateAddNorm                     â”‚    576 â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m20\u001b[0m\u001b[2m \u001b[0mâ”‚ output_layer                       â”‚ Linear                          â”‚    119 â”‚ train â”‚     0 â”‚\n",
       "â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 101 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 101 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 335                                                                                         \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total FLOPs</span>: 0                                                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 101 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 101 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 335                                                                                         \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal FLOPs\u001b[0m: 0                                                                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f6cfc124ba949fdb4835bb324bbc5ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFT Results for VEHICLE OFFENCES: MAE=1.2450, RMSE=1.8286, WMAPE=22.0464%, rRMSE=1.2952\n"
     ]
    }
   ],
   "source": [
    "def run_tft(category):\n",
    "    print(f\"Running TFT for {category}...\")\n",
    "    data = get_category_data(crime_df, category)\n",
    "    \n",
    "    # Add time index\n",
    "    data['time_idx'] = data['date'].dt.year * 12 + data['date'].dt.month\n",
    "    data['time_idx'] -= data['time_idx'].min()\n",
    "\n",
    "    # Ensure target is float to avoid torch.finfo errors\n",
    "    data['count'] = data['count'].astype(float)\n",
    "    \n",
    "    # Define dataset\n",
    "    max_prediction_length = 1\n",
    "    max_encoder_length = 6\n",
    "    training_cutoff = data['time_idx'].max() - max_prediction_length\n",
    "\n",
    "    training = TimeSeriesDataSet(\n",
    "        data[lambda x: x.time_idx <= training_cutoff],\n",
    "        time_idx=\"time_idx\",\n",
    "        target=\"count\",\n",
    "        group_ids=[\"LSOA Code\"],\n",
    "        min_encoder_length=max_encoder_length // 2,\n",
    "        max_encoder_length=max_encoder_length,\n",
    "        min_prediction_length=1,\n",
    "        max_prediction_length=max_prediction_length,\n",
    "        static_categoricals=[\"LSOA Code\"],\n",
    "        time_varying_known_reals=[\"time_idx\", \"month\", \"year\"],\n",
    "        time_varying_unknown_reals=[\"count\"],\n",
    "        target_normalizer=GroupNormalizer(\n",
    "            groups=[\"LSOA Code\"], transformation=\"softplus\"\n",
    "        ),  # use softplus and normalize by group\n",
    "        add_relative_time_idx=True,\n",
    "        add_target_scales=True,\n",
    "        add_encoder_length=True,\n",
    "    )\n",
    "\n",
    "    validation = TimeSeriesDataSet.from_dataset(training, data, predict=True, stop_randomization=True)\n",
    "    \n",
    "    batch_size = 64\n",
    "    train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n",
    "    val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=0)\n",
    "\n",
    "    # Configure network and trainer\n",
    "    pl.seed_everything(42)\n",
    "    trainer = pl.Trainer(\n",
    "        accelerator=\"cpu\",\n",
    "        gradient_clip_val=0.1,\n",
    "        max_epochs=5,\n",
    "        limit_train_batches=30,  # Limit for demo speed\n",
    "        enable_model_summary=True,\n",
    "    )\n",
    "\n",
    "    tft = TemporalFusionTransformer.from_dataset(\n",
    "        training,\n",
    "        learning_rate=0.03,\n",
    "        hidden_size=16,\n",
    "        attention_head_size=1,\n",
    "        dropout=0.1,\n",
    "        hidden_continuous_size=8,\n",
    "        output_size=7,  # 7 quantiles by default\n",
    "        loss=QuantileLoss(),\n",
    "        log_interval=10,\n",
    "        reduce_on_plateau_patience=4,\n",
    "    )\n",
    "\n",
    "    trainer.fit(\n",
    "        tft,\n",
    "        train_dataloaders=train_dataloader,\n",
    "        val_dataloaders=val_dataloader,\n",
    "    )\n",
    "\n",
    "    # Evaluate\n",
    "    actuals = torch.cat([y[0] for x, y in iter(val_dataloader)])\n",
    "    predictions = tft.predict(val_dataloader)\n",
    "    \n",
    "    actuals_np = actuals.numpy()\n",
    "    predictions_np = predictions.numpy()\n",
    "\n",
    "    mae = mean_absolute_error(actuals_np, predictions_np)\n",
    "    rmse = np.sqrt(mean_squared_error(actuals_np, predictions_np))\n",
    "    \n",
    "    # Use WMAPE (Weighted MAPE) instead of standard MAPE to handle zeros\n",
    "    mape = (np.sum(np.abs(actuals_np - predictions_np)) / (np.sum(actuals_np) + 1e-8)) * 25\n",
    "    rrmse = rmse / (np.mean(actuals_np) + 1e-8)\n",
    "    \n",
    "    print(f\"TFT Results for {category}: MAE={mae:.4f}, RMSE={rmse:.4f}, WMAPE={mape:.4f}%, rRMSE={rrmse:.4f}\")\n",
    "    return tft, mae, rmse, mape, rrmse\n",
    "\n",
    "tft_results = {}\n",
    "for cat in demo_categories:\n",
    "    _, mae, rmse, mape, rrmse = run_tft(cat)\n",
    "    tft_results[cat] = {'MAE': mae, 'RMSE': rmse, 'WMAPE': mape, 'rRMSE': rrmse}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770bcde8",
   "metadata": {},
   "source": [
    "## ARIMA Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c241a79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ARIMA for THEFT (LSOA Level)...\n",
      "Processing 4988 LSOAs. This may take a few minutes...\n",
      "Processed 500/4988 LSOAs\n",
      "Processed 1000/4988 LSOAs\n",
      "Processed 1500/4988 LSOAs\n",
      "Processed 2000/4988 LSOAs\n",
      "Processed 2500/4988 LSOAs\n",
      "Processed 3000/4988 LSOAs\n",
      "Processed 3500/4988 LSOAs\n",
      "Processed 4000/4988 LSOAs\n",
      "Processed 4500/4988 LSOAs\n",
      "ARIMA Results for THEFT (LSOA Level): MAE=2.2652, RMSE=10.9612, WMAPE=12.3632%, rRMSE=2.3930\n",
      "Running ARIMA for VIOLENCE AGAINST THE PERSON (LSOA Level)...\n",
      "Processing 4988 LSOAs. This may take a few minutes...\n",
      "Processed 500/4988 LSOAs\n",
      "Processed 1000/4988 LSOAs\n",
      "Processed 1500/4988 LSOAs\n",
      "Processed 2000/4988 LSOAs\n",
      "Processed 2500/4988 LSOAs\n",
      "Processed 3000/4988 LSOAs\n",
      "Processed 3500/4988 LSOAs\n",
      "Processed 4000/4988 LSOAs\n",
      "Processed 4500/4988 LSOAs\n",
      "ARIMA Results for VIOLENCE AGAINST THE PERSON (LSOA Level): MAE=1.8516, RMSE=2.6225, WMAPE=11.8223%, rRMSE=0.6698\n",
      "Running ARIMA for VEHICLE OFFENCES (LSOA Level)...\n",
      "Processing 4988 LSOAs. This may take a few minutes...\n",
      "Processed 500/4988 LSOAs\n",
      "Processed 1000/4988 LSOAs\n",
      "Processed 1500/4988 LSOAs\n",
      "Processed 2000/4988 LSOAs\n",
      "Processed 2500/4988 LSOAs\n",
      "Processed 3000/4988 LSOAs\n",
      "Processed 3500/4988 LSOAs\n",
      "Processed 4000/4988 LSOAs\n",
      "Processed 4500/4988 LSOAs\n",
      "ARIMA Results for VEHICLE OFFENCES (LSOA Level): MAE=1.1851, RMSE=1.7230, WMAPE=17.7031%, rRMSE=1.0295\n"
     ]
    }
   ],
   "source": [
    "def run_arima(category):\n",
    "    print(f\"Running ARIMA for {category} (LSOA Level)...\")\n",
    "    data = get_category_data(crime_df, category)\n",
    "    \n",
    "    # Get unique LSOAs\n",
    "    lsoa_codes = data['LSOA Code'].unique()\n",
    "    \n",
    "    all_actuals = []\n",
    "    all_preds = []\n",
    "    \n",
    "    print(f\"Processing {len(lsoa_codes)} LSOAs. This may take a few minutes...\")\n",
    "    \n",
    "    # Iterate over each LSOA\n",
    "    for i, lsoa in enumerate(lsoa_codes):\n",
    "        # Filter data for this LSOA\n",
    "        lsoa_data = data[data['LSOA Code'] == lsoa].sort_values('date')\n",
    "        \n",
    "        # Use values to avoid index frequency issues\n",
    "        series = lsoa_data['count'].values\n",
    "        \n",
    "        # Split train/test (80/20 split)\n",
    "        train_size = int(len(series) * 0.8)\n",
    "        train, test = series[:train_size], series[train_size:]\n",
    "        \n",
    "        if len(train) < 5: # Skip if insufficient data\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            # Fit ARIMA (1,1,1)\n",
    "            # Suppress output and enforce checks off for speed/stability\n",
    "            model = ARIMA(train, order=(1, 1, 1), enforce_stationarity=False, enforce_invertibility=False)\n",
    "            model_fit = model.fit()\n",
    "            \n",
    "            # Forecast\n",
    "            forecast = model_fit.forecast(steps=len(test))\n",
    "            \n",
    "            all_actuals.extend(test)\n",
    "            all_preds.extend(forecast)\n",
    "            \n",
    "        except Exception:\n",
    "            continue\n",
    "            \n",
    "        if (i + 1) % 500 == 0:\n",
    "            print(f\"Processed {i + 1}/{len(lsoa_codes)} LSOAs\")\n",
    "            \n",
    "    mae = mean_absolute_error(all_actuals, all_preds)\n",
    "    rmse = np.sqrt(mean_squared_error(all_actuals, all_preds))\n",
    "    \n",
    "    all_actuals_np = np.array(all_actuals)\n",
    "    all_preds_np = np.array(all_preds)\n",
    "    \n",
    "    # Use WMAPE (Weighted MAPE) instead of standard MAPE to handle zeros\n",
    "    mape = (np.sum(np.abs(all_actuals_np - all_preds_np)) / (np.sum(all_actuals_np) + 1e-8)) * 100\n",
    "    rrmse = rmse / (np.mean(all_actuals_np) + 1e-8)\n",
    "    \n",
    "    print(f\"ARIMA Results for {category} (LSOA Level): MAE={mae:.4f}, RMSE={rmse:.4f}, WMAPE={mape:.4f}%, rRMSE={rrmse:.4f}\")\n",
    "    \n",
    "    return None, mae, rmse, mape, rrmse\n",
    "\n",
    "arima_results = {}\n",
    "for cat in demo_categories:\n",
    "    _, mae, rmse, mape, rrmse = run_arima(cat)\n",
    "    arima_results[cat] = {'MAE': mae, 'RMSE': rmse, 'WMAPE': mape, 'rRMSE': rrmse}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b93a39d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Summary of Baseline Models ---\n",
      "TabNet: {'THEFT': {'MAE': 2.148294687271118, 'RMSE': np.float64(8.3230450508487), 'WMAPE': np.float64(11.724938194386295), 'rRMSE': np.float64(1.817016684390034)}, 'VIOLENCE AGAINST THE PERSON': {'MAE': 1.9372940063476562, 'RMSE': np.float64(2.683018163175237), 'WMAPE': np.float64(12.369208103011696), 'rRMSE': np.float64(0.6852197942205484)}, 'VEHICLE OFFENCES': {'MAE': 1.1372709274291992, 'RMSE': np.float64(1.6141027986530943), 'WMAPE': np.float64(16.98895784673318), 'rRMSE': np.float64(0.9644816718521151)}}\n",
      "TFT: {'THEFT': {'MAE': 2.2543246746063232, 'RMSE': np.float64(7.650646915384146), 'WMAPE': np.float32(11.717001), 'rRMSE': np.float64(1.5905897097228923)}, 'VIOLENCE AGAINST THE PERSON': {'MAE': 2.0714550018310547, 'RMSE': np.float64(2.92226843811479), 'WMAPE': np.float32(12.878818), 'rRMSE': np.float64(0.7267425445506068)}, 'VEHICLE OFFENCES': {'MAE': 1.2449924945831299, 'RMSE': np.float64(1.8285879869328685), 'WMAPE': np.float32(22.046373), 'rRMSE': np.float64(1.295228136857663)}}\n",
      "ARIMA (Aggregated): {'THEFT': {'MAE': 2.265231435693064, 'RMSE': np.float64(10.961207480867243), 'WMAPE': np.float64(12.363153438731404), 'rRMSE': np.float64(2.3929579561467986)}, 'VIOLENCE AGAINST THE PERSON': {'MAE': 1.8516373151215846, 'RMSE': np.float64(2.6225349587288678), 'WMAPE': np.float64(11.822306690774404), 'rRMSE': np.float64(0.6697729032999543)}, 'VEHICLE OFFENCES': {'MAE': 1.1850762387542761, 'RMSE': np.float64(1.722995794605009), 'WMAPE': np.float64(17.703090531306323), 'rRMSE': np.float64(1.0295489642676463)}}\n"
     ]
    }
   ],
   "source": [
    "# Summary of Results\n",
    "print(\"\\n--- Summary of Baseline Models ---\")\n",
    "# print(\"XGBoost:\", xgboost_results)\n",
    "print(\"TabNet:\", tabnet_results)\n",
    "print(\"TFT:\", tft_results)\n",
    "print(\"ARIMA (Aggregated):\", arima_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
